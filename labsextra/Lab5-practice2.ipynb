{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0a2c5-444a-400d-afd2-5d25b17ded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup basic variables\n",
    "properties = LoadProperties()\n",
    "\n",
    "# Declare username and password and dsn (data connection string)\n",
    "un = \"vector\"\n",
    "pw = \"vector\"\n",
    "cs = \"localhost/FREEPDB1\"\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn23c = oracledb.connect(user=un, password=pw, dsn=cs)\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92c884-ebf7-4882-bf60-3bbf698e17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we will prepare using ConversationalRetrievalChain\n",
    "# with memory. We use a LLM model and also pass conversation history\n",
    "# in query. We will use Oracle vectorstore.\n",
    "\n",
    "# Step 1 - here we create a function that creates a chain\n",
    "\n",
    "def create_chain():\n",
    "    embed_model = OCIGenAIEmbeddings(\n",
    "        model_id=properties.getEmbeddingModelName(),\n",
    "        service_endpoint=properties.getEndpoint(),\n",
    "        compartment_id=properties.getCompartment(),\n",
    "        auth_type=\"INSTANCE_PRINCIPAL\"\n",
    "    )\n",
    "\n",
    "    vs = OracleVS.from_existing_index(embed_model,\n",
    "                client=conn23c, table_name=\"DEMO_TABLE\",\n",
    "                distance_strategy=DistanceStrategy.DOT_PRODUCT)\n",
    "\n",
    "    retrv = vs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "    llm = ChatOracle(\n",
    "        model_id=properties.getModelName(),\n",
    "        service_endpoint=properties.getEndpoint(),\n",
    "        compartment_id=properties.getCompartment(),\n",
    "        auth_type=\"INSTANCE_PRINCIPAL\",\n",
    "        model_kwargs={\"max_tokens\": 2000}\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferMemory(llm=llm,\n",
    "                memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    qa = ConversationalRetrievalChain.from_llm(llm,\n",
    "                retriever=retrv, memory=memory)\n",
    "\n",
    "    return qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ecd5-f7e0-4396-83da-996d5fcf474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - here we declare a chat function\n",
    "\n",
    "def chat(llm_chain, user_input):\n",
    "    # generate a prediction for a prompt\n",
    "    bot_response = llm_chain.invoke(user_input)\n",
    "    return bot_response['bot_response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d7e9a-37dd-4c3e-b8dd-be077a4907df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - here we setup streamlit text input and pass input text to chat function\n",
    "# chat function returns the response and we print it.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import streamlit as st\n",
    "\n",
    "    st.subheader(\"Chatbot that answers your study questions\")\n",
    "    col1, col2 = st.columns([4,1])\n",
    "\n",
    "    def initialize_session_state():\n",
    "        if \"llm_chain\" not in st.session_state:\n",
    "            st.session_state.llm_chain = create_chain()\n",
    "            st.session_state.messages = []\n",
    "        return st.session_state.llm_chain\n",
    "\n",
    "    user_input = st.chat_input(\"Ask me a question about science\")\n",
    "    with col1:\n",
    "        if user_input:\n",
    "            llm_chain = initialize_session_state()\n",
    "            bot_response = chat(llm_chain, user_input)\n",
    "            print(\"BOT_RESPONSE>>>> \", bot_response)\n",
    "\n",
    "            st.session_state.messages.append({\"role\": \"chatbot\", \"content\": bot_response})\n",
    "            st.write(\"User: \", user_input)\n",
    "            st.write(\"Chatbot: \", bot_response)\n",
    "\n",
    "    for message in st.session_state.messages:\n",
    "        st.chat_message(\"assistant\").write(message[\"content\"])\n",
    "\n",
    "        st.chat_message(\"user\").write(message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ac584-a4ee-4478-a244-dbbacbb84c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run chatbot-streamlit.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
