{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8582d28e-e667-4333-940a-d22369c5ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot-streamlit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot-streamlit.py\n",
    "\n",
    "import oracledb\n",
    "import oci\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from LoadProperties import LoadProperties\n",
    "\n",
    "print(\"Successfully imported libraries and modules\")\n",
    "\n",
    "# Setup basic variables\n",
    "properties = LoadProperties()\n",
    "\n",
    "# Declare username and password and dsn (data connection string)\n",
    "un = \"vector\"\n",
    "pw = \"vector\"\n",
    "cs = \"localhost/FREEPDB1\"\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn23c = oracledb.connect(user=un, password=pw, dsn=cs)\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection failed!\", e)\n",
    "\n",
    "# Step 1 - create the chain\n",
    "def create_chain():\n",
    "    embed_model = OCIGenAIEmbeddings(\n",
    "        model_id=properties.getEmbeddingModelName(),\n",
    "        service_endpoint=properties.getEndpoint(),\n",
    "        compartment_id=properties.getCompartment(),\n",
    "        auth_type=\"INSTANCE_PRINCIPAL\",\n",
    "    )\n",
    "\n",
    "    vs = OracleVS(\n",
    "        embedding_function=embed_model,\n",
    "        client=conn23c,\n",
    "        table_name=\"DEMO_TABLE\",\n",
    "        distance_strategy=DistanceStrategy.DOT_PRODUCT,\n",
    "    )\n",
    "\n",
    "    retv = vs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "    llm = ChatOCIGenAI(\n",
    "        model_id=properties.getModelName(),\n",
    "        service_endpoint=properties.getEndpoint(),\n",
    "        compartment_id=properties.getCompartment(),\n",
    "        auth_type=\"INSTANCE_PRINCIPAL\",\n",
    "        model_kwargs={\"max_tokens\": 200},\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        llm=llm,\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True,\n",
    "        output_key=\"answer\",\n",
    "    )\n",
    "\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm, retriever=retv, memory=memory, return_source_documents=True\n",
    "    )\n",
    "    return qa\n",
    "\n",
    "# Step 2 - define chat function\n",
    "def chat(llm_chain, user_input):\n",
    "    # generate a prediction for a prompt\n",
    "    bot_json = llm_chain.invoke(user_input)\n",
    "    return {\"bot_response\": bot_json}\n",
    "\n",
    "\n",
    "# Step 3 - Streamlit app interface\n",
    "if __name__ == \"__main__\":\n",
    "    import streamlit as st\n",
    "\n",
    "    st.subheader(\"Chatbot that answers your study questions\")\n",
    "    col1, col2 = st.columns([4, 1])\n",
    "\n",
    "    def initialize_session_state():\n",
    "        if \"llm_chain\" not in st.session_state:\n",
    "            st.session_state[\"llm_chain\"] = create_chain()\n",
    "        return st.session_state[\"llm_chain\"]\n",
    "\n",
    "    user_input = st.chat_input()\n",
    "\n",
    "    with col1:\n",
    "        col1.subheader(\"------Ask me a question about science chapters------\")\n",
    "        # col2.subheader(\"References\")\n",
    "\n",
    "        if \"messages\" not in st.session_state:\n",
    "            st.session_state.messages = []\n",
    "\n",
    "        if user_input:\n",
    "            llm_chain = initialize_session_state()\n",
    "            bot_response = chat(llm_chain, user_input)\n",
    "            print(\"bot_response->\\n\", bot_response)\n",
    "            st.session_state.messages.append({\n",
    "                \"role\": \"chatbot\",\n",
    "                \"content\": bot_response\n",
    "            })\n",
    "\n",
    "        for message in st.session_state.messages:\n",
    "            st.chat_message(\"user\").write(\n",
    "                \"Question: \" + str(message[\"content\"][\"bot_response\"].get(\"question\", \"[No Question Found]\"))\n",
    "            )\n",
    "\n",
    "            st.chat_message(\"assistant\").write(\n",
    "                \"Answer: \" + str(message[\"content\"][\"bot_response\"].get(\"answer\", \"[No Answer Found]\"))\n",
    "            )\n",
    "\n",
    "            for doc in message[\"content\"][\"bot_response\"].get(\"source_documents\", []):\n",
    "                st.chat_message(\"assistant\").write(\n",
    "                    \"Chunk Id Is: \" + str(doc.metadata[\"id\"]) +\n",
    "                    \"\\n-page->\" + str(doc.metadata[\"link\"])\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82266653-e9f5-4633-b153-f756506bf712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.0.0.73:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://89.168.86.230:8501\u001b[0m\n",
      "\u001b[0m\n",
      "Successfully imported libraries and modules\n",
      "Connection successful!\n",
      "Successfully imported libraries and modules\n",
      "Connection successful!\n",
      "bot_response->\n",
      " {'bot_response': {'question': 'how many modules are there in the AI foundation course?', 'chat_history': [HumanMessage(content='how many modules are there in the AI foundation course?'), AIMessage(content='There are six modules in the AI Foundations course.')], 'answer': 'There are six modules in the AI Foundations course.', 'source_documents': [Document(metadata={'id': '0', 'link': 'Page 0'}, page_content=\"Course Name: Oracle Cloud Infrastructure AI Foundations Module 1: Welcome to AI Foundations  1.1 Welcome to AI Foundations  [AUDIO LOGO] Hello, and welcome to the course introduction to the OCI AI Foundations 2023 course. I'm Hemant Gahankari. I'm a senior principal training lead at Oracle University and will take you through this overview of the course. The course instructor for this course are Hemant Gahankari-- that is myself-- Himanshu Raj, and Nick Commisso. The content for this course has been contributed by Hemant Gahankari, Himanshu Raj, Kiran BR, Rohit Rahi, Anuradha Srinivasaraghavan, and Roshini Varghese. This course is intended for anyone who wants to begin learning about AI and ML, for example, Cloud engineers or architects, or IT professionals, or even students who want to upskill but have no prior exposure to AI/ML in the past, though familiarity with OCI or similar Cloud Services is recommended. This course is split into six modules. The first one is AI foundations. In this module, you will learn about foundational AI concepts and you will learn to differentiate between AI, ML, and DL, that is, artificial intelligence, machine learning, and deep learning. In this second module, you will dive deeper into machine learning and learn about supervised, unsupervised, and reinforcement learning. In the third module, you will learn about a variety of neural network architectures, like artificial neural network, convolutional neural network, recurrent neural network, and long-/short-term memory targeted at solving problems that need using complex data like images, videos, audio, or even text. In the fourth module, we will explore generative AI and LLMs. In this module, you will learn about basics of LLMs, that is, large language models, and transformers. You will also learn about prompt engineering and fine-tuning of LLMs\"), Document(metadata={'id': '2', 'link': 'Page 2'}, page_content=\"And finally, go through the exam preparation video and take the OCI AI Foundations 2023 exam itself. We believe in you and know that you have what it takes to succeed. Keep up the excellent work, and I'll see you at the next milestone on your journey towards completing the course. Thanks for watching.   Module2: AI Foundations  2.1 Module Intro [AUDIO LOGO] Hi, and welcome to this module on foundations. My name is Nick, and I'm a senior cloud engineer here at Oracle. And I'm so grateful that you're here. Now before we dive in, let's take a look at some of the objectives of this module. By the end of the module, you'll be able to explain AI concepts, describe common AI domains and tasks and distinguish between artificial intelligence, machine learning, and deep learning. Now, let's dive in. 2.2 Introduction to AI [AUDIO LOGO] So what is artificial intelligence? Well, the ability of machines to imitate the cognitive abilities and problem solving capabilities of human intelligence can be classified as artificial intelligence or AI. So what capabilities or abilities are we referring to? Well, let's take a look. Human intelligence is the intellectual capability of humans that allows us to learn new skills through observation and mental digestion, to think through and understand abstract concepts and apply reasoning, to communicate using a language and understand the nonverbal queues such as facial recognition, tone variation, and body language. You can handle objections in real time, even in a complex setting. You can plan for short and long-term situations or projects. And, of course, you can create music and art or invent something new like an original idea. If you can replicate any of these human capabilities in machines, this is artificial general intelligence or AGI. So in other words, AGI can mimic human sensory and motor skills, performance, learning, and intelligence and use these abilities to carry out complicated tasks without human intervention\"), Document(metadata={'id': '14', 'link': 'Page 14'}, page_content=\"Let's explore what neural networks are. To make tricky things work, we use layers of neurons. Neural networks are like a bunch of connected brain cells stacked together. They're an example of a supervised machine learning algorithm that is perhaps the best understood in the context of functional approximation. Functional approximation involves estimating a hidden function by examining past or currently known data from the specific domain. Generative AI, a subset of machine learning, creates diverse content like text, audio, images, and more. These models, often powered by neural networks, learn patterns from existing data to craft fresh and creative output. For instance, ChatGPT generates text-based responses by understanding patterns in text data that it's been trained on. Generative AI plays a vital role in various AI tasks requiring content creation and innovation.  Module 3: Machine Learning Foundations  3.1 Module Intro [AUDIO LOGO] Hi. My name is Hemant, and I'm a senior principal training lead at Oracle University. I welcome you to this module. In this module, we will begin with foundational machine learning concepts. After that, we will dive into supervised learning, more specifically linear regression and logistic regression. Following that, we will also learn about unsupervised learning. And to end with, we will also explore and learn reinforcement learning. So, let's begin. 3.2 Introduction to Machine Learning [AUDIO LOGO] Hello. In this lesson, we will learn about machine learning. Machine learning is a subset of artificial intelligence that focuses on creating computer systems that can learn and improve from experience without being explicitly programmed. It is powered by algorithms that incorporate intelligence into the machines by automatically learning from the data it consumes. Let us explore an example to understand how it works. Consider a pup being taught to differentiate between a ball and a book\")]}}\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run chatbot-streamlit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f75d17-94b0-4413-8e7e-079417c3cb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
